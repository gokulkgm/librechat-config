version: 1.1.5

cache: true

endpoints:
  custom:
    # groq
    # Model list: https://console.groq.com/settings/limits
    - name: "groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
          "llama-3.1-405b-reasoning",
          "llama-3.1-70b-versatile",
          "llama-3.1-8b-instant",
          "mixtral-8x7b-32768",
          "gemma-7b-it",
          "gemma2-9b-it"
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"
    
    # OpenRouter.ai
    # Model list: https://openrouter.ai/models
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "openrouter/auto",
          "---ANTHROPIC---",
          "anthropic/claude-3.5-sonnet",
          "---DEEPSEEK---",
          "deepseek/deepseek-chat",
          "---GOOGLE---",
          "google/gemini-flash-1.5",
          "google/gemini-pro",
          "google/gemini-pro-1.5",
          "google/gemini-pro-1.5-exp",
          "google/gemini-pro-vision",
          "---META-LLAMA---",
          "meta-llama/llama-3.1-405b",
          "meta-llama/llama-3.1-405b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "---MISTRALAI---",
          "mistralai/codestral-mamba",
          "mistralai/mixtral-8x22b-instruct",
          "mistralai/mixtral-8x7b",
          "mistralai/mixtral-8x7b-instruct",
          "---OPENAI---",
          "openai/gpt-3.5-turbo",
          "openai/gpt-4o",
          "openai/gpt-4o-mini",
          "openai/o1-mini",
          "openai/o1-preview",
          "---QWEN---",
          "qwen/qwen-110b-chat",
          "---OTHERS---",
          ]
        fetch: false
      dropParams: ["stop"]
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    # Unify
    # Model list: https://unify.ai/chat
    - name: "Unify"
      apiKey: "${UNIFY_API_KEY}"
      baseURL: "https://api.unify.ai/v0/"
      models:
        default: [
          "router@q:1|c:2.12e-01|t:5.00e-04|i:2.78e-04",
          "chatgpt-4o-latest@openai",
          "gpt-3.5-turbo@openai",
          "gpt-4-turbo@openai",
          "gpt-4@openai",
          "gpt-4o-2024-08-06@openai",
          "gpt-4o-mini@openai",
          "gpt-4o@openai",
          "claude-3-haiku@anthropic",
          "claude-3-opus@anthropic",
          "claude-3-sonnet@anthropic",
          "claude-3.5-sonnet@anthropic",
          "claude-3-haiku@aws-bedrock",
          "claude-3-opus@aws-bedrock",
          "claude-3-sonnet@aws-bedrock",
          "claude-3.5-sonnet@aws-bedrock",
          "command-r-plus@aws-bedrock",
          "llama-3-70b-chat@aws-bedrock",
          "llama-3-8b-chat@aws-bedrock",
          "llama-3.1-405b-chat@aws-bedrock",
          "llama-3.1-70b-chat@aws-bedrock",
          "llama-3.1-8b-chat@aws-bedrock",
          "mistral-7b-instruct-v0.2@aws-bedrock",
          "mistral-large@aws-bedrock",
          "mixtral-8x7b-instruct-v0.1@aws-bedrock",
          "codellama-13b-instruct@fireworks-ai",
          "codellama-34b-instruct@fireworks-ai",
          "gemma-2-9b-it@fireworks-ai",
          "gemma-7b-it@fireworks-ai",
          "llama-3-70b-chat@fireworks-ai",
          "llama-3-8b-chat@fireworks-ai",
          "llama-3.1-405b-chat@fireworks-ai",
          "llama-3.1-70b-chat@fireworks-ai",
          "llama-3.1-8b-chat@fireworks-ai",
          "mistral-7b-instruct-v0.1@fireworks-ai",
          "mistral-7b-instruct-v0.2@fireworks-ai",
          "mistral-7b-instruct-v0.3@fireworks-ai",
          "mistral-nemo@fireworks-ai",
          "mixtral-8x22b-instruct-v0.1@fireworks-ai",
          "mixtral-8x7b-instruct-v0.1@fireworks-ai",
          "qwen-2-72b-instruct@fireworks-ai",
          "codellama-13b-instruct@octoai",
          "codellama-34b-instruct@octoai",
          "codellama-7b-instruct@octoai",
          "llama-3-70b-chat@octoai",
          "llama-3-8b-chat@octoai",
          "llama-3.1-405b-chat@octoai",
          "llama-3.1-70b-chat@octoai",
          "llama-3.1-8b-chat@octoai",
          "mistral-7b-instruct-v0.2@octoai",
          "mistral-7b-instruct-v0.3@octoai",
          "mixtral-8x22b-instruct-v0.1@octoai",
          "mixtral-8x7b-instruct-v0.1@octoai",
          "qwen-2-7b-instruct@octoai",
          "codellama-13b-instruct@together-ai",
          "codellama-34b-instruct@together-ai",
          "codellama-70b-instruct@together-ai",
          "codellama-7b-instruct@together-ai",
          "deepseek-coder-33b-instruct@together-ai",
          "gemma-2b-it@together-ai",
          "gemma-7b-it@together-ai",
          "llama-3-70b-chat@together-ai",
          "llama-3-8b-chat@together-ai",
          "llama-3.1-405b-chat@together-ai",
          "llama-3.1-70b-chat@together-ai",
          "llama-3.1-8b-chat@together-ai",
          "mistral-7b-instruct-v0.1@together-ai",
          "mistral-7b-instruct-v0.2@together-ai",
          "mistral-7b-instruct-v0.3@together-ai",
          "mixtral-8x22b-instruct-v0.1@together-ai",
          "mixtral-8x7b-instruct-v0.1@together-ai",
          "phind-codellama-34b-v2@together-ai",
          "qwen-2-72b-instruct@together-ai",
          "codellama-34b-instruct@deepinfra",
          "gemma-2-27b-it@deepinfra",
          "gemma-2-9b-it@deepinfra",
          "gemma-7b-it@deepinfra",
          "llama-3-70b-chat@deepinfra",
          "llama-3-8b-chat@deepinfra",
          "llama-3.1-405b-chat@deepinfra",
          "llama-3.1-70b-chat@deepinfra",
          "llama-3.1-8b-chat@deepinfra",
          "mistral-7b-instruct-v0.1@deepinfra",
          "mistral-7b-instruct-v0.3@deepinfra",
          "mixtral-8x22b-instruct-v0.1@deepinfra",
          "mixtral-8x7b-instruct-v0.1@deepinfra",
          "nemotron-4-340b-instruct@deepinfra",
          "phi-3-medium-4k-instruct@deepinfra",
          "phind-codellama-34b-v2@deepinfra",
          "qwen-2-72b-instruct@deepinfra",
          "qwen-2-7b-instruct@deepinfra",
          "codellama-34b-instruct@perplexity-ai",
          "llama-3.1-70b-chat@perplexity-ai",
          "llama-3.1-8b-chat@perplexity-ai",
          "mistral-7b-instruct-v0.2@perplexity-ai",
          "mixtral-8x7b-instruct-v0.1@perplexity-ai",
          "gemini-1.5-flash@vertex-ai",
          "gemini-1.5-pro@vertex-ai",
          "gemma-2-9b-it@vertex-ai",
          "gemma-2-9b-it@groq",
          "gemma-7b-it@groq",
          "llama-3-70b-chat@groq",
          "llama-3-8b-chat@groq",
          "mixtral-8x7b-instruct-v0.1@groq",
          "gemma-7b-it@lepton-ai",
          "llama-3-70b-chat@lepton-ai",
          "llama-3-8b-chat@lepton-ai",
          "llama-3.1-405b-chat@lepton-ai",
          "llama-3.1-70b-chat@lepton-ai",
          "llama-3.1-8b-chat@lepton-ai",
          "mistral-7b-instruct-v0.3@lepton-ai",
          "mixtral-8x7b-instruct-v0.1@lepton-ai",
          "gpt-4o-mini@azure-ai",
          "gpt-4o@azure-ai",
          "llama-3.1-405b-chat@azure-ai",
          "llama-3.1-70b-chat@azure-ai",
          "llama-3.1-8b-chat@azure-ai",
          "llama-3-70b-chat@replicate",
          "llama-3-8b-chat@replicate",
          "llama-3.1-405b-chat@replicate",
          "mistral-7b-instruct-v0.2@replicate",
          "mixtral-8x7b-instruct-v0.1@replicate",
          "mistral-7b-instruct-v0.2@mistral-ai",
          "mistral-7b-instruct-v0.3@mistral-ai",
          "mistral-large@mistral-ai",
          "mistral-nemo@mistral-ai",
          "mistral-small@mistral-ai",
          "mixtral-8x22b-instruct-v0.1@mistral-ai",
          "mixtral-8x7b-instruct-v0.1@mistral-ai",
          ]
        fetch: false
      titleConvo: true
      titleModel: "router@q:1|c:2.12e-01|t:5.00e-04|i:2.78e-04"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]
